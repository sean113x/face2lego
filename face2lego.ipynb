{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "face2lego",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sean113x/face2lego/blob/main/face2lego.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_s8h-ilzHQc"
      },
      "source": [
        "### colab from : https://www.justinpinkney.com/toonify-yourself/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzDuIoMcqfBT",
        "outputId": "d7eaafd7-7cb3-4b92-ce9a-f6a5adbb578d"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "!git clone https://github.com/justinpinkney/stylegan2\n",
        "%cd stylegan2\n",
        "!nvcc test_nvcc.cu -o test_nvcc -run\n",
        "\n",
        "!mkdir raw\n",
        "!mkdir aligned\n",
        "!mkdir generated"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Cloning into 'stylegan2'...\n",
            "remote: Enumerating objects: 269, done.\u001b[K\n",
            "remote: Total 269 (delta 0), reused 0 (delta 0), pack-reused 269\u001b[K\n",
            "Receiving objects: 100% (269/269), 2.32 MiB | 5.33 MiB/s, done.\n",
            "Resolving deltas: 100% (141/141), done.\n",
            "/content/stylegan2\n",
            "CPU says hello.\n",
            "GPU says hello.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IppG8Z8O19R"
      },
      "source": [
        "## Upload your own photos\n",
        "\n",
        "Upload your photos to `raw/`. These don't need to be aligned as we'll use a face detector to grab all the faces and transform them into the correct format. One note of caution is that you'll need a pretty high-resolution picture of a face to get a sharp result (the final face crop is resized to 1024x1024 pixels)\n",
        "\n",
        "We'll grab a example image from the internet to work with.\n",
        "\n",
        "The basic process is:\n",
        "- Extract faces and align the images\n",
        "- Project the images (i.e. find the latent code)\n",
        "- Toonify the images (i.e. use the latent code with the toon model)\n",
        "\n",
        "Results will be placed in the stylegan2/generated folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-2oM_L8VWYZ",
        "outputId": "b298dde1-d58e-4925-e3f6-f74ec5cf8121"
      },
      "source": [
        "!wget https://upload.wikimedia.org/wikipedia/commons/6/6d/Shinz%C5%8D_Abe_Official.jpg -O raw/example.jpg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-23 02:19:16--  https://upload.wikimedia.org/wikipedia/commons/6/6d/Shinz%C5%8D_Abe_Official.jpg\n",
            "Resolving upload.wikimedia.org (upload.wikimedia.org)... 208.80.154.240, 2620:0:861:ed1a::2:b\n",
            "Connecting to upload.wikimedia.org (upload.wikimedia.org)|208.80.154.240|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 332712 (325K) [image/jpeg]\n",
            "Saving to: ‘raw/example.jpg’\n",
            "\n",
            "\rraw/example.jpg       0%[                    ]       0  --.-KB/s               \rraw/example.jpg     100%[===================>] 324.91K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2021-08-23 02:19:16 (6.35 MB/s) - ‘raw/example.jpg’ saved [332712/332712]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_kbwt_Dl-Ck",
        "outputId": "12409180-eb1c-488d-b927-1029d93f9182"
      },
      "source": [
        "!gdown --id 14oy0KsAP17-ini0TS_PUUYEyZby3NegL -O raw/kyumi.jpg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=14oy0KsAP17-ini0TS_PUUYEyZby3NegL\n",
            "To: /content/stylegan2/raw/kyumi.jpg\n",
            "\r  0% 0.00/222k [00:00<?, ?B/s]\r100% 222k/222k [00:00<00:00, 33.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwVXBFaSuoIU",
        "outputId": "79980797-64d9-4d19-dde8-70ada8ffcaea"
      },
      "source": [
        "import pretrained_networks\n",
        "\n",
        "blended_url = \"https://drive.google.com/uc?id=\" \n",
        "ffhq_url = \"http://d36zk2xti64re0.cloudfront.net/stylegan2/networks/stylegan2-ffhq-config-f.pkl\"\n",
        "\n",
        "_, _, Gs_blended = pretrained_networks.load_networks(blended_url)\n",
        "_, _, Gs = pretrained_networks.load_networks(ffhq_url)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://drive.google.com/uc?id=1UyEXt8JnTZlyT7iXYfmfyxk68nL0lWhT .... done\n",
            "Setting up TensorFlow plugin \"fused_bias_act.cu\": Preprocessing... Compiling... Loading... Done.\n",
            "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Preprocessing... Compiling... Loading... Done.\n",
            "Downloading http://d36zk2xti64re0.cloudfront.net/stylegan2/networks/stylegan2-ffhq-config-f.pkl ... done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLUH060th5oQ",
        "outputId": "ee10bc84-b84d-48a2-d58b-44d53a119cfc"
      },
      "source": [
        "!python align_images.py raw aligned"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
            "64045056/64040097 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldHXNMYhnYC5",
        "outputId": "d24e44da-c5fc-46fa-a8b4-70a31f7b38f2"
      },
      "source": [
        "!python project_images.py --num-steps 500 aligned generated"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading networks from \"http://d36zk2xti64re0.cloudfront.net/stylegan2/networks/stylegan2-ffhq-config-f.pkl\"...\n",
            "Setting up TensorFlow plugin \"fused_bias_act.cu\": Preprocessing... Loading... Done.\n",
            "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Preprocessing... Loading... Done.\n",
            "Downloading http://d36zk2xti64re0.cloudfront.net/stylegan1/networks/metrics/vgg16_zhang_perceptual.pkl ... done\n",
            "Loading images from \".stylegan2-tmp/dataset/images\"\n",
            "detected 1 images ...\n",
            "Creating dataset \".stylegan2-tmp/dataset/tfrecords\"\n",
            "Adding the images to tfrecords ...\n",
            "added images 0\n",
            "Added 1 images.\n",
            "Projecting image \"example_01.png\"...\n",
            "Loading images from \".stylegan2-tmp/dataset/images\"\n",
            "detected 1 images ...\n",
            "Creating dataset \".stylegan2-tmp/dataset/tfrecords\"\n",
            "Adding the images to tfrecords ...\n",
            "added images 0\n",
            "Added 1 images.\n",
            "Projecting image \"kyumi_01.png\"...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHQgAO2yqaew"
      },
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "from pathlib import Path\n",
        "\n",
        "latent_dir = Path(\"generated\")\n",
        "latents = latent_dir.glob(\"*.npy\")\n",
        "for latent_file in latents:\n",
        "  latent = np.load(latent_file)\n",
        "  latent = np.expand_dims(latent,axis=0)\n",
        "  synthesis_kwargs = dict(output_transform=dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=False), minibatch_size=8)\n",
        "  images = Gs_blended.components.synthesis.run(latent, randomize_noise=False, **synthesis_kwargs)\n",
        "  Image.fromarray(images.transpose((0,2,3,1))[0], 'RGB').save(latent_file.parent / (f\"{latent_file.stem}-lego.jpg\"))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcWXgS5DXata"
      },
      "source": [
        "from IPython.display import Image \n",
        "embedded = Image(filename=\"generated/example_01.png\", width=256)\n",
        "display(embedded)\n",
        "tooned = Image(filename=\"generated/example_01-lego.jpg\", width=256)\n",
        "display(tooned)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}